{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the parts needed\n",
    "#%pip install gym pyvirtualdisplay matplotlib\n",
    "#%pip install gym[atari]\n",
    "#%pip install gym[accept-rom-license]\n",
    "#%pip install sklearn -qq\n",
    "#%pip install scikit-image -qq\n",
    "#%pip install torchvision -qq\n",
    "#%pip install tensorflow -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "#import torch.nn.functional as F\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow.compat.v1 as tf\n",
    "ACTIONS = 4\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameprocess(frame,frame_height=84, frame_width=84):\n",
    "\n",
    "    frame_height = frame_height\n",
    "    frame_width = frame_width\n",
    "    processed = tf.image.rgb_to_grayscale(frame)\n",
    "    processed = tf.image.crop_to_bounding_box(processed, 34, 0, 160, 140)\n",
    "    processed = tf.image.resize_images(processed, \n",
    "                                            [frame_height, frame_width], \n",
    "                                            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectOutput(records,previous_spikes):\n",
    "    print(\"RECORDS\",records)\n",
    "    out = np.array([0 for _ in range(64)])\n",
    "    if records==[]:\n",
    "        return random.randint(0,ACTIONS-1)\n",
    "    for record in records[0]:\n",
    "        out[record]+=1\n",
    "    return np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atari(object):\n",
    "    \"\"\"Wrapper for the environment provided by gym\"\"\"\n",
    "    def __init__(self, envName, no_op_steps=10, agent_history_length=4):\n",
    "        self.env = gym.make(envName)\n",
    "        self.state = None\n",
    "        self.last_lives = 0\n",
    "        self.no_op_steps = no_op_steps\n",
    "        self.metadata = self.env.metadata\n",
    "        self.agent_history_length = agent_history_length\n",
    "        self.spec = self.env.spec\n",
    "        self.action_space = self.env.action_space\n",
    "        self.render = self.env.render\n",
    "\n",
    "    def reset(self,evaluation=False):\n",
    "        frame = self.env.reset()\n",
    "        processed_frame = frameprocess(frame)\n",
    "        self.state = np.repeat(processed_frame, self.agent_history_length, axis=2)\n",
    "\n",
    "    def step(self,action):\n",
    "        new_frame, reward, done, info = self.env.step(action)\n",
    "        processed_new_frame = frameprocess(new_frame) \n",
    "        new_state = np.append(self.state[:, :, 1:], processed_new_frame, axis=2) \n",
    "        self.state = new_state\n",
    "        \n",
    "        return processed_new_frame, reward, done, new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def inputToSpikeRateArray(frame):\n",
    "    f = np.array(frame)\n",
    "    return f.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyNN.spiNNaker as p\n",
    "DA_concentration = [0]*actions\n",
    "\n",
    "def run_spinnaker_sim(input_label, output_label, connection_port):\n",
    "    global DA_concentration\n",
    "    \n",
    "    tau_c = 1000  # Eligibility trace decay time constant.\n",
    "    tau_d = 200  # Dopamine trace decay time constant.\n",
    "      # Dopamine trace step increase size\n",
    "    inputpopsize = 84*84\n",
    "    # Set up the simulation itself\n",
    "    p.setup(1.0)\n",
    "\n",
    "    ##### INPUT LAYER #####\n",
    "    input_pop = p.Population(inputpopsize,p.external_devices.SpikeInjector(\n",
    "            database_notify_port_num=connection_port),label = input_label)\n",
    "    ##### REWARD LAYER #####\n",
    "    reward_pop = [p.Population(10,p.external_devices.SpikeInjector(database_notify_port_num=connection_port)) for _ in range(actions)]\n",
    "\n",
    "    #####   STDP    #####\n",
    "    timing_rule = p.SpikePairRule(tau_plus=0.1, tau_minus=0.1, A_plus=0.1, A_minus=0.1)\n",
    "    weight_rule = p.AdditiveWeightDependence(w_max=10.0, w_min=0.01)\n",
    "    stdp_model_excitatory = p.STDPMechanism(timing_dependence=timing_rule, weight_dependence=weight_rule, weight=5)\n",
    "    \n",
    "    #### OUTPUT LAYER ####\n",
    "    output_pop = [p.Population(int(100),p.IF_curr_exp(),label = output_label) for action in range(4)]\n",
    "    \n",
    "    ## Create dopaminergic connection\n",
    "    k=0\n",
    "    for pop in output_pop:      \n",
    "        p.Projection(\n",
    "            input_pop,pop,\n",
    "            p.AllToAllConnector(),\n",
    "            synapse_type=stdp_model_excitatory)\n",
    "        \n",
    "        p.Projection(\n",
    "            reward_pop[k],pop,\n",
    "            p.AllToAllConnector(),\n",
    "            synapse_type=p.extra_models.Neuromodulation(\n",
    "            weight=DA_concentration[k], tau_c=tau_c, tau_d=tau_d, w_max=20.0, w_min=0),\n",
    "            receptor_type='reward', label='reward synapses')\n",
    "        \n",
    "        k+=1\n",
    "\n",
    "    \n",
    "    # Make the population output spikes\n",
    "    for op in output_pop:\n",
    "        p.external_devices.activate_live_output_for(\n",
    "            op, database_notify_port_num=connection_port)\n",
    "\n",
    "    # Run in sections of 20ms\n",
    "    p.external_devices.run_forever(sync_time=20)\n",
    "    \n",
    "    # End the simulation once complete (run_forever stops when requested elsewhere)\n",
    "    p.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import pyNN.spiNNaker as p\n",
    "\n",
    "\n",
    "# Note the odd order of parameters here is because input_label and connection\n",
    "# are from the default interface, but output_label and spike_queue are from\n",
    "# additional parameters\n",
    "def run_openai_gym_sim(input_label, connection, output_label, spike_queue, new_spike_queue, plt, img, env):\n",
    "\n",
    "    observation = env.reset()\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "    previous_spikes = []\n",
    "    while True:\n",
    "        print(total_reward)\n",
    "        step += 1\n",
    "        \n",
    "        # Display the simulation at the start of the step\n",
    "        #img.set_data(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        action,previous_spikes = selectOutput(new_spike_queue,previous_spikes)\n",
    "        \n",
    "        # TODO: Pull from the spike queue and use them to \"decide the action\"\n",
    "        while spike_queue:\n",
    "            label, time, neuron_ids = spike_queue.pop()\n",
    "        \n",
    "        # Move the simulation forwards\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # If finished, stop\n",
    "        if done:\n",
    "            print(f\"Steps: {step}, score: {total_reward}\")\n",
    "            break\n",
    "            \n",
    "        # TODO: Use the output from the environment to send spikes to SpiNNaker\n",
    "        connection.send_spikes(input_label,inputToSpikeRateArray(env.env.state))#SPIKES TO BE SENT)\n",
    "        \n",
    "        # Continue spinnaker simulation for next run of loop\n",
    "        p.external_devices.continue_simulation()\n",
    "        \n",
    "    # Stop the OpenAI Gym\n",
    "    #env.env.close()\n",
    "    \n",
    "    # Stop SpiNNaker\n",
    "    p.external_devices.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pulator\n",
    "import pyNN.spiNNaker as p\n",
    "from functools import partial\n",
    "from collections import deque\n",
    "\n",
    "# A queue of spikes\n",
    "spike_queue = deque()\n",
    "new_spike_queue = []\n",
    "# A function to receive spikes and put them in a queue\n",
    "def receive_spikes(label, time, neuron_ids):\n",
    "    spike_queue.appendleft((label, time, neuron_ids))\n",
    "    new_spike_queue = []\n",
    "    new_spike_queue.append((label, time, neuron_ids))\n",
    "\n",
    "# Keep track of the labels these need to match up in several places\n",
    "input_label = \"input\"\n",
    "output_label = \"output\"\n",
    "\n",
    "# Create the connection.\n",
    "# Note the use of local_port=None allows the automatic assignment of a port.\n",
    "connection = p.external_devices.SpynnakerLiveSpikesConnection(\n",
    "    local_port=None, send_labels=[input_label], receive_labels=[output_label])\n",
    "\n",
    "# Make the OpenAI Gym simulation\n",
    "env = Atari(\"Breakout-v0\")\n",
    "env = wrappers.Monitor(env, \"/tmp/Breakout-v0\", force=True)\n",
    "\n",
    "# Display Breakout-v0 = plt.figure(figsize=(5, 5))\n",
    "img = None#plt.imshow(env.env.render(mode='rgb_array'))\n",
    "\n",
    "# Register the OpenAI Gym function to be called when the simulation starts\n",
    "# Note: we have to use a label here so we chose input_label\n",
    "connection.add_start_resume_callback(\n",
    "    input_label, partial(run_openai_gym_sim, output_label=output_label, spike_queue=spike_queue, new_spike_queue=new_spike_queue, plt=plt, img=img, env=env))\n",
    "\n",
    "# Register the receive spikes function\n",
    "connection.add_receive_callback(output_label, receive_spikes)\n",
    "\n",
    "# Run the simulation\n",
    "run_spinnaker_sim(input_label, output_label, connection.local_port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1231/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 sec per frame is a good time allowing me to run a few thousand cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sPyNNakerGit",
   "language": "python",
   "name": "spynnakergit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
